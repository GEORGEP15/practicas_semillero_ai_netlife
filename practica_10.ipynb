{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0508879-e6f2-472d-8956-5590e827c252",
   "metadata": {},
   "source": [
    "# Taller 10: Tu Primer Embedding - Vectorizar Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e1db6-3f2b-4f41-92c6-3050c105a196",
   "metadata": {},
   "source": [
    "## üéØ Objetivo\n",
    "\n",
    "Entender qu√© es un embedding viendo c√≥mo se convierte texto en una lista de n√∫meros y midiendo similitud entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81549a8-0575-4c1f-bac0-7172bc94039b",
   "metadata": {},
   "source": [
    "## Paso 1: Instalaci√≥n de librer√≠a\n",
    "\n",
    "Instalar√°s dos paquetes principales:\n",
    "\n",
    "- sentence-transformers: Es la biblioteca que transforma frases en vectores inteligentes.\n",
    "\n",
    "- numpy y scikit-learn: Para manipulaci√≥n de n√∫meros y c√°lculo de similitud.\n",
    "\n",
    "- tf-keras: Biblioteca necesaria para que funcione sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f4be6c-d211-4419-a213-71316643fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.2.6)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.32.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /usr/local/lib/python3.12/dist-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.29.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/.local/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.42.0)\n",
      "Requirement already satisfied: rich in /usr/lib/python3/dist-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/lib/python3/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers numpy tf-keras scikit-learn --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b10fc-dfc1-4c1a-9136-c872da819330",
   "metadata": {},
   "source": [
    "## Paso 2: Importar Librer√≠as y cargar modelo preentrenado\n",
    "\n",
    "¬øQu√© har√°s exactamente?\n",
    "Cargar√°s 3 herramientas esenciales:\n",
    "\n",
    "- SentenceTransformer: La clase principal que convierte texto en embeddings (vectores).\n",
    "\n",
    "- cosine_similarity (de scikit-learn): Calcula qu√© tan parecidos son dos vectores.\n",
    "\n",
    "- numpy: Ayuda a manipular arrays de n√∫meros (los embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fbd9ab-62a8-43f0-b686-e15d02f7731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo cargado exitosamente!\n",
      "üìä Dimensi√≥n de embeddings: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Cargar modelo preentrenado (se descarga autom√°ticamente la primera vez)\n",
    "# Peso del modelo: ~80MB\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"‚úÖ Modelo cargado exitosamente!\")\n",
    "print(f\"üìä Dimensi√≥n de embeddings: {model.get_sentence_embedding_dimension()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3815b-1af5-43bc-b8b7-9fd530a2d5a4",
   "metadata": {},
   "source": [
    "## Paso 3: Preparar Frases de Prueba\n",
    "\n",
    "Se cargan en un array las frases a vectorizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29312be-5583-4a5d-bc16-d84bc5ba72b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Frases a vectorizar:\n",
      "  1. Docker container est√° lento\n",
      "  2. Docker container se demora\n",
      "  3. Mi loro pasa volando\n",
      "  4. Mi gato duerme todo el d√≠a\n"
     ]
    }
   ],
   "source": [
    "frases = [\n",
    "    \"Docker container est√° lento\",\n",
    "    \"Docker container se demora\",\n",
    "    \"Mi loro pasa volando\",\n",
    "    \"Mi gato duerme todo el d√≠a\"\n",
    "]\n",
    "\n",
    "print(\"üìÑ Frases a vectorizar:\")\n",
    "for i, frase in enumerate(frases, 1):\n",
    "    print(f\"  {i}. {frase}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142cd39-912a-4b01-bc8f-49730e06188d",
   "metadata": {},
   "source": [
    "## Paso 4: Generar Embeddings \n",
    "Usar√°s el m√©todo .encode() del modelo para convertir autom√°ticamente todas tus 4 frases en embeddings en una sola l√≠nea de c√≥digo. El modelo procesa cada frase internamente y genera un vector num√©rico para cada una.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ad610c-9721-4b08-b012-b758299fb6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Generando embeddings...\n",
      "‚úÖ Embeddings generados!\n",
      "üìä Shape (forma): (4, 384)\n",
      "   - 4 frases\n",
      "   - 384 dimensiones por frase\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Generando embeddings...\")\n",
    "embeddings = model.encode(frases)\n",
    "\n",
    "print(f\"‚úÖ Embeddings generados!\")\n",
    "print(f\"üìä Shape (forma): {embeddings.shape}\")\n",
    "print(f\"   - {embeddings.shape[0]} frases\")\n",
    "print(f\"   - {embeddings.shape[1]} dimensiones por frase\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b947b-25d8-41c4-b46e-ccbcebce222d",
   "metadata": {},
   "source": [
    "## Paso 5: Comparar Embeddings Visualmente\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b964e5-14fe-4813-bb1b-5c7898d1dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Comparaci√≥n r√°pida (primeros 4 n√∫meros):\n",
      "\n",
      "FRASE                              | Embedding (5 primeros n√∫meros)\n",
      "-------------------------------------------------------------------------------------\n",
      "1. Docker container est√° lento         | [ 0.038  0.048 -0.033 -0.043  0.041...]\n",
      "2. Docker container no inicia          | [-0.000  0.063 -0.008 -0.029  0.012...]\n",
      "3. Mi loro pasa volando                | [-0.046  0.048  0.019 -0.034 -0.099...]\n",
      "4. Mi gato duerme todo el d√≠a          | [-0.091  0.075  0.028 -0.014 -0.020...]\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Comparaci√≥n r√°pida (primeros 4 n√∫meros):\\n\")\n",
    "\n",
    "print(\"FRASE                              | Embedding (5 primeros n√∫meros)\")\n",
    "print(\"-\" * 85)\n",
    "for i, (frase, embedding) in enumerate(zip(frases, embeddings), 1):\n",
    "    # Formatear para ver solo 3 decimales\n",
    "    emb_str = \" \".join([f\"{x:6.3f}\" for x in embedding[:5]])\n",
    "    print(f\"{i}. {frase:35} | [{emb_str}...]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
